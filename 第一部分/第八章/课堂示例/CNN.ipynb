{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(num_features=16)\n",
    "        self.fc1 = nn.Linear(in_features=8*8*16, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = out.view(-1, 8*8*16)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.cifar.CIFAR10, torchvision.datasets.cifar.CIFAR10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'D:\\FunnyProgramming\\PythonProject\\SummerPrac\\data'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "type(cifar10), type(cifar10_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imgs: Maximum: 2.094577, Minimum: -1.989213\n",
      "Imgs_val: Maximum: 2.094577, Minimum: -1.782841\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.stack([img for img, label in cifar10], dim=3) # 这里dim=3主要为了比较好算mean和dev\n",
    "imgs_val = torch.stack([img for img, label in cifar10_val], dim=3)\n",
    "mean_imgs, stddev_imgs = imgs.view(3, -1).mean(dim=-1), imgs.view(3, -1).std(dim=-1)\n",
    "mean_imgs_val, stddev_imgs_val = imgs_val.view(3, -1).mean(dim=-1), imgs_val.view(3, -1).std(dim=-1)\n",
    "normal_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, \n",
    "                                  transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean_imgs, std=stddev_imgs)]))\n",
    "normal_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, \n",
    "                                  transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean_imgs, std=stddev_imgs)]))\n",
    "print(\"Imgs: Maximum: %f, Minimum: %f\" % (normal_cifar10[0][0].max(), normal_cifar10[0][0].min()))\n",
    "print(\"Imgs_val: Maximum: %f, Minimum: %f\" % (normal_cifar10_val[0][0].max(), normal_cifar10_val[0][0].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0, 2:1}\n",
    "cifar2 = [(img,label_map[label]) for img, label in normal_cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img,label_map[label]) for img, label in normal_cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-27 20:55:14.918840 Epoch: 1, Average Loss: 0.41888475142846443\n",
      "2023-08-27 20:55:20.331441 Epoch: 10, Average Loss: 0.2201342896149037\n",
      "2023-08-27 20:55:26.121497 Epoch: 20, Average Loss: 0.12901126930288448\n",
      "2023-08-27 20:55:31.945586 Epoch: 30, Average Loss: 0.0639505622920337\n",
      "2023-08-27 20:55:37.752588 Epoch: 40, Average Loss: 0.03093684478633248\n",
      "2023-08-27 20:55:43.579638 Epoch: 50, Average Loss: 0.007562966479706299\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "device = torch.device('cuda')\n",
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device=device)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    total_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out = model(imgs)\n",
    "        loss = loss_fn(out, labels)\n",
    "        total_loss += loss.detach().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print(\"{} Epoch: {}, Average Loss: {}\".format(datetime.datetime.now(), epoch, total_loss/len(train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=-1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((labels == predicted).sum())\n",
    "    print(\"Accuracy {}: {:.2f}\".format(name, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
